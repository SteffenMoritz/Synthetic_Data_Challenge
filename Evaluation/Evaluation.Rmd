---
title: SAT Dataset Evaluation Report - Method FCS
subtitle: Use Case School testing
author: Steffen Moritz, Hariolf Merkle, Felix Geyer, Michel Reiffert, Reinhard Tent (DESTATIS)
date: January 28, 2022
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
    toc: true
# pdf_document:
#    toc: true
#    toc_depth: 1
---




```{r setup, include=FALSE}
## Global options
knitr::opts_chunk$set(cache = TRUE)
```

```{r dataset, include=FALSE}
# Load Source Dataset
load(here::here("results/sm_sat_gan_ctgan_epoch1000.rda"))
load(here::here("satgpa.rda"))
original <- as.data.frame(satgpa)
synthetic <- as.data.frame(result_gan)
```
# Executive Summary
According to our results FCS is only partially useful for the use case xyz with the SAT data. In comparison to methods xza and yzt it lacks utility. Scores for our main metric was xxx compared to xxx. Also for risk it seems like it is not a good idea. As the use case reuqires to have xxx and xxx and also provides full data to . An advantage of the method we see is the easy way to apply and processing speed for huge datasets.


The method you used
Whether or not you used any specific tooling to generate your synthetic data

How you evaluated your data (specify any specific measures and their results).

Created both a fully synthetic and a partially synthetic file
Evidence of tuning

# Dataset and Use Case considerations
Challenges we faced with the SAT datset were ... it was important for us to keep ... sum ..
For privacy we argued that ...

# Method considerations
Overall full ... seems to be a good choice for ... 

# Privacy and Risk Evaluation

## Measuring Disclosure Risk - An Improvement of Uniqueness-Measure:

Starting point for our considerations was the matching on unique records method as described in the chapter on disclosure risk measures in the starter guide. The R package synthpop provided us with an easy to use implementation of this method: replicated.uniques. While using it we noticed that the meaningfulness of this measure is quite limited, if numeric variables are contained in the data. For example, one of the issues is the fact that you cannot match features, if they consist of a different number of decimals.
Additionally, in our opinion not only exact matches of unique data are troublesome, but also “almost exact” matches. Imagine a dataset with information about the respondents’ income. If for a unique person in the original dataset there exists a matching data point in the synthetic dataset that only differs in the income by 2%, the original function would not identify this as a match. So we borrowed the notion of the p% rule from cell suppression methods which identifies a data point as critical, if one can guess the original values with some error of at most p%.

With that in mind, we implemented a function generate_uniques_pp that gives a Uniqueness-Measure for “almost exact” matches. We used this measure on all the synthetic data sets of the challenge. 

```{r, echo=FALSE, warning = FALSE, message= FALSE}
library(synthpop)
library(dplyr)

generate_uniques_for_sat <-function(df_orig, df_synth, exclude = NULL){
  syn_synth <- list(m = 1, syn = df_synth)
  replicated.uniques(object = syn_synth, data = df_orig , exclude = exclude)
}

generate_uniques_pp_for_sat <-function(df_orig, df_synth,identifiers = 1:4 ,  p = 0.05){
  syn_synth <- list(m = 1, syn = df_synth[,identifiers])
  syn_orig <- list(m = 1, syn = df_orig[,identifiers])
  
  repl_synth <- replicated.uniques(object = syn_synth, data = df_orig[,identifiers])$replications
  repl_orig <- replicated.uniques(object = syn_orig, data = df_synth[,identifiers])$replications
  

  df <- inner_join(df_synth[repl_synth,], df_orig[repl_orig,], 
                   by=names(df_orig)[identifiers], 
                   suffix = c("_synth", "_orig"))
  
  count_disclosure <- df %>%
    mutate(hs_gpa_diff = abs(hs_gpa_synth-hs_gpa_orig)/abs(hs_gpa_orig), 
           fy_gpa_diff = abs(fy_gpa_synth-fy_gpa_orig)/abs(fy_gpa_orig) ) %>%
    filter(hs_gpa_diff < p | fy_gpa_diff < p)%>%
    count(.)
  result = list(replications_uniques = sum(repl_synth),
                count_disclosure = count_disclosure[1,1], per_disclosure = 100*count_disclosure[1,1]/nrow(df_synth))
}

# Disclosure Risk
disclosure <- generate_uniques_for_sat(original, synthetic)


pp3 <- data.frame(`Number Uniques` = c( disclosure$no.uniques), 
                 `Number Replications` = c(disclosure$no.replications ),  
                 `Percentage Replications` = c(disclosure$per.replications)
                 )


kbl(pp3) %>%
  kable_paper(full_width = F) 
```

replications_uniques
Number of unique data in the synthetic dataset that have an identifier combination that can also be found in the original dataset.

count_disclosure
Number of synthetic data that are too close to the original data. We identify two data as "too close" if their identifiers are equal and if there exists at least one additional features for which the original value and the synthetic value differ by at most p%. 
 
per_disclosure
The proportion of synthetic data that are too close to original data relative to the original dataset size.

```{r privacy metrics, echo=FALSE, warning = FALSE, message= FALSE}
library(synthpop)
library(dplyr)

generate_uniques_for_sat <-function(df_orig, df_synth, exclude = NULL){
  syn_synth <- list(m = 1, syn = df_synth)
  replicated.uniques(object = syn_synth, data = df_orig , exclude = exclude)
}

generate_uniques_pp_for_sat <-function(df_orig, df_synth,identifiers = 1:4 ,  p = 0.05){
  syn_synth <- list(m = 1, syn = df_synth[,identifiers])
  syn_orig <- list(m = 1, syn = df_orig[,identifiers])
  
  repl_synth <- replicated.uniques(object = syn_synth, data = df_orig[,identifiers])$replications
  repl_orig <- replicated.uniques(object = syn_orig, data = df_synth[,identifiers])$replications
  

  df <- inner_join(df_synth[repl_synth,], df_orig[repl_orig,], 
                   by=names(df_orig)[identifiers], 
                   suffix = c("_synth", "_orig"))
  
  count_disclosure <- df %>%
    mutate(hs_gpa_diff = abs(hs_gpa_synth-hs_gpa_orig)/abs(hs_gpa_orig), 
           fy_gpa_diff = abs(fy_gpa_synth-fy_gpa_orig)/abs(fy_gpa_orig) ) %>%
    filter(hs_gpa_diff < p | fy_gpa_diff < p)%>%
    count(.)
  result = list(replications_uniques = sum(repl_synth),
                count_disclosure = count_disclosure[1,1], per_disclosure = 100*count_disclosure[1,1]/nrow(df_synth))
}


synthetic$hs_gpa <- round(synthetic$hs_gpa,2)
synthetic$fy_gpa <- round(synthetic$fy_gpa,2)

# Disclosure Risk  - selbstentwickelt
disclosure_own <- generate_uniques_pp_for_sat(original, synthetic)



# Data Frame Own Metric
pp <- data.frame(`Replications Unique` = disclosure_own$replications_uniques, `Count Disclosure` = disclosure_own$count_disclosure, `Percentage Disclosure` = disclosure_own$per_disclosure)




library("kableExtra")



kbl(pp) %>%
  kable_paper(full_width = F) 

```


## Perceived Disclosure Risk: 
Unique records in the synthetical dataset may be mistaken for unique records in the original data. This may lead to disadvantages for the underlying respondent, even if the record of the synthetical record differs significantly to the original record  in the confidential variable. The perceived risk is measured by matching the unique records among the datasets based on the identifying variables, e.g. sex, age, adress. We applied the method replicated.uniques of the synthpop-R-package. There is no fixed threshold that must not be exceeded in this measure, however, a smaller percentage of unique matchings is preferred to minimize the perceived disclosure risk. 





```{r, echo=FALSE, warning = FALSE, message= FALSE}
# Disclosure Risk
#disclosure <- generate_uniques_for_sat(original, synthetic)

# Perceived disclosure risk
disclosure_percei <- generate_uniques_for_sat(original, synthetic, exclude = c("hs_gpa", "fy_gpa") )


pp2 <- data.frame( 
                 `Number Uniques` = c(disclosure_percei$no.uniques), 
                 `Number Replications` = c(disclosure_percei$no.replications),  
                 `Percentage Replications` = c(disclosure_percei$per.replications)
                 )

#pp3 <- data.frame(`Metric` = c("Perceived Risk", "Actual Risk"), 
#                 `Number Uniques` = c(disclosure_percei$no.uniques, disclosure$no.uniques), 
#                 `Number Replications` = c(disclosure_percei$no.replications,disclosure$no.replications ),  
#                `Percentage Replications` = c(disclosure_percei$per.replications, disclosure$per.replications)
#                 )


kbl(pp2) %>%
  kable_paper(full_width = F) 
```



# Utility Evaluation

par(mfrow = c(1,2))
mean(results_sm_sat_gan_ctgan_epoch1000$ks > 0.05)
results_sm_sat_gan_ctgan_epoch1000$comp
results_sm_sat_gan_ctgan_epoch1000$il
corrplot(results_sm_sat_gan_ctgan_epoch1000$cp1$corr, method = "color", type = "lower", main = "Original")
corrplot(results_sm_sat_gan_ctgan_epoch1000$cp2$corr, method = "color", type = "lower", main = "Synthetic")
results_sm_sat_gan_ctgan_epoch1000$ug
results_sm_sat_gan_ctgan_epoch1000$ut


# Tuning and Optimizations